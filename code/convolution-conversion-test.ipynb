{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function `torch_conv_layer_to_affine` takes a `torch.nn.Conv2d` layer `conv`\n",
    "and produces an equivalent `torch.nn.Linear` layer `fc`.\n",
    "Specifically, this means that the following holds for `x` of a valid shape:\n",
    "    torch.flatten(conv(x)) == fc(torch.flatten(x))\n",
    "Or equivalently:\n",
    "    conv(x) == fc(torch.flatten(x)).reshape(conv(x).shape)\n",
    "allowing of course for some floating-point error.\n",
    "\"\"\"\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "def torch_conv_layer_to_affine(\n",
    "    conv: torch.nn.Conv2d, input_size: Tuple[int, int]\n",
    ") -> torch.nn.Linear:\n",
    "    w, h = input_size\n",
    "    # Formula from the Torch docs:\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "    output_size = [\n",
    "            (input_size[i] + 2 * conv.padding[i] - conv.kernel_size[i]) // conv.stride[i]\n",
    "    + 1\n",
    "    for i in [0, 1]\n",
    "        ]\n",
    "    \n",
    "    in_shape = (conv.in_channels, w, h)\n",
    "    out_shape = (conv.out_channels, output_size[0], output_size[1])\n",
    "    fc = nn.Linear(in_features=np.product(in_shape), out_features=np.product(out_shape))\n",
    "    fc.weight.data.fill_(0.0)\n",
    "\n",
    "    # Output coordinates\n",
    "    for xo, yo in range2d(output_size[0], output_size[1]):\n",
    "        # The upper-left corner of the filter in the input tensor\n",
    "        xi0 = -conv.padding[0] + conv.stride[0] * xo\n",
    "        yi0 = -conv.padding[1] + conv.stride[1] * yo\n",
    "        # Position within the filter\n",
    "        for xd, yd in range2d(conv.kernel_size[0], conv.kernel_size[1]):\n",
    "            # Output channel\n",
    "            for co in range(conv.out_channels):\n",
    "                fc.bias[enc_tuple((co, xo, yo), out_shape)] = conv.bias[co]\n",
    "                for ci in range(conv.in_channels):\n",
    "                    # Make sure we are within the input image (and not in the padding)\n",
    "                    if 0 <= xi0 + xd < w and 0 <= yi0 + yd < h:\n",
    "                        cw = conv.weight[co, ci, xd, yd]\n",
    "                        # Flatten the weight position to 1d in \"canonical ordering\",\n",
    "                        # i.e. guaranteeing that:\n",
    "                        # FC(img.reshape(-1)) == Conv(img).reshape(-1)\n",
    "                        fc.weight[\n",
    "                        enc_tuple((co, xo, yo), out_shape),\n",
    "                        enc_tuple((ci, xi0 + xd, yi0 + yd), in_shape),\n",
    "                                                ] = cw\n",
    "    return fc\n",
    "\n",
    "def range2d(to_a, to_b):\n",
    "    for a in range(to_a):\n",
    "        for b in range(to_b):\n",
    "            yield a, b\n",
    "\n",
    "def enc_tuple(tup: Tuple, shape: Tuple) -> int:\n",
    "    res = 0\n",
    "    coef = 1\n",
    "    for i in reversed(range(len(shape))):\n",
    "        assert tup[i] < shape[i]\n",
    "        res += coef * tup[i]\n",
    "        coef *= shape[i]\n",
    "    return res\n",
    "\n",
    "def dec_tuple(x: int, shape: Tuple) -> Tuple:\n",
    "    res = []\n",
    "    for i in reversed(range(len(shape))):\n",
    "        res.append(x % shape[i])\n",
    "        x //= shape[i]\n",
    "        return tuple(reversed(res))\n",
    "\n",
    "def test_tuple_encoding():\n",
    "    x = enc_tuple((3, 2, 1), (5, 6, 7))\n",
    "    assert dec_tuple(x, (5, 6, 7)) == (3, 2, 1)\n",
    "    print(\"Tuple encoding ok\")\n",
    "\n",
    "def test_layer_conversion():\n",
    "    for stride in [1, 2]:\n",
    "        for padding in [0, 1, 2]:\n",
    "            for filter_size in [3, 4]:\n",
    "                img = torch.rand((1, 2, 6, 7))\n",
    "                conv = nn.Conv2d(2, 5, filter_size, stride=stride, padding=padding)\n",
    "                fc = torch_conv_layer_to_affine(conv, img.shape[2:])\n",
    "                # Also checks that our encoding flattens the inputs/outputs such that\n",
    "                # FC(flatten(img)) == flatten(Conv(img))\n",
    "                res1 = fc(img.reshape((-1))).reshape(conv(img).shape)\n",
    "                res2 = conv(img)\n",
    "                worst_error = (res1 - res2).max()\n",
    "                print(\"Output shape\", res2.shape, \"Worst error: \", float(worst_error))\n",
    "                assert worst_error <= 1.0e-6\n",
    "                print(\"Layer conversion ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "import torchvision.transforms.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(cv2.imread('images/castle.jpg'))[...,::-1]/255.0\n",
    "\n",
    "# values from https://pytorch.org/vision/main/models/generated/torchvision.models.vgg16.html\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).reshape(1,-1,1,1)\n",
    "std  = torch.Tensor([0.229, 0.224, 0.225]).reshape(1,-1,1,1)\n",
    "\n",
    "X = (torch.FloatTensor(img[np.newaxis].transpose([0,3,1,2])*1) - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.vgg19(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(483)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = None\n",
    "for *parent, k in [k.split('.') for k, m in model.named_modules() if type(m).__name__ == 'Conv2d']:\n",
    "    layer = model.get_submodule('.'.join(parent))[int(k)]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]),\n",
       " torch.Size([1, 64, 224, 224]),\n",
       " torch.Size([64, 3, 3, 3]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, layer.forward(X).shape, layer.weight.shape, layer.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnp = X.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = layer.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = layer.bias.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (3, 4)\n",
    "H = 224\n",
    "W = 224\n",
    "Cout = 64\n",
    "padding = (1, 1)\n",
    "\n",
    "X_pad = np.array([[\n",
    "    np.pad(x, padding, 'constant', constant_values=(0, 0)) for x in Xnp[0]]])\n",
    "\n",
    "output = np.zeros((1, Cout, H, W))\n",
    "for k in range(Cout):\n",
    "    kernel = weights[k]\n",
    "\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            zone = X_pad[0,:,i:i+kernel_size[0],j:j+kernel_size[1]]\n",
    "            product = np.tensordot(zone, kernel, axes=3)\n",
    "            result = product + biases[k]\n",
    "            output[0,k,i,j] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-4.35848653e-01, -2.76941657e-01, -2.86430359e-01, ...,\n",
       "           7.58498907e-01,  7.56732941e-01,  4.38061357e-01],\n",
       "         [-3.96351993e-01, -2.71862268e-01, -2.84331560e-01, ...,\n",
       "           7.47735977e-01,  7.46625900e-01,  4.61679697e-01],\n",
       "         [-3.92981827e-01, -2.72107422e-01, -2.70687878e-01, ...,\n",
       "           7.38332510e-01,  7.37986922e-01,  4.65240717e-01],\n",
       "         ...,\n",
       "         [-1.86877537e+00, -2.27427530e+00, -2.35830474e+00, ...,\n",
       "          -1.39870453e+00, -1.32285511e+00, -1.21387553e+00],\n",
       "         [-1.74284554e+00, -2.03332281e+00, -2.27975750e+00, ...,\n",
       "          -1.45715129e+00, -1.37679887e+00, -1.28719878e+00],\n",
       "         [-1.40771985e+00, -1.46523333e+00, -1.65783656e+00, ...,\n",
       "          -9.74298537e-01, -1.01699233e+00, -1.07208538e+00]],\n",
       "\n",
       "        [[ 1.62007064e-01,  4.67999279e-01,  4.79892820e-01, ...,\n",
       "           8.34800184e-01,  8.69134188e-01,  1.78299916e+00],\n",
       "         [-1.59164339e-01,  2.77136236e-01,  3.30293924e-01, ...,\n",
       "           1.96036294e-01,  2.49110237e-01,  1.67158937e+00],\n",
       "         [-1.07872874e-01,  3.24014723e-01,  3.72142553e-01, ...,\n",
       "           2.61011034e-01,  2.26912111e-01,  1.66034937e+00],\n",
       "         ...,\n",
       "         [ 3.99579573e+00,  2.34091878e-01,  9.27852988e-01, ...,\n",
       "          -5.72833359e-01, -2.81613708e-01, -8.57530236e-01],\n",
       "         [ 3.14297223e+00,  1.21219957e+00,  2.13652301e+00, ...,\n",
       "           4.20884609e-01,  3.48329663e-01, -6.55727088e-01],\n",
       "         [ 3.49355149e+00,  2.52715111e+00,  4.56610680e+00, ...,\n",
       "           1.00002837e+00,  1.13164163e+00,  3.69906932e-01]],\n",
       "\n",
       "        [[-1.25432646e+00, -1.49930859e+00, -1.51244259e+00, ...,\n",
       "          -1.48164654e+00, -1.49309874e+00, -1.29796851e+00],\n",
       "         [-1.23249006e+00, -1.64541519e+00, -1.67593598e+00, ...,\n",
       "          -1.79481268e+00, -1.80478764e+00, -1.50515985e+00],\n",
       "         [-1.24115956e+00, -1.67595625e+00, -1.66321373e+00, ...,\n",
       "          -1.81898475e+00, -1.82345629e+00, -1.49373126e+00],\n",
       "         ...,\n",
       "         [-3.30369520e+00, -3.02207446e+00, -2.82705188e+00, ...,\n",
       "          -1.75334954e+00, -1.71825624e+00, -1.62301314e+00],\n",
       "         [-3.08956051e+00, -2.70376849e+00, -3.12073064e+00, ...,\n",
       "          -2.21377182e+00, -2.02596712e+00, -1.84267545e+00],\n",
       "         [-2.88644361e+00, -2.61959267e+00, -3.34184790e+00, ...,\n",
       "          -1.70126545e+00, -1.76340985e+00, -1.76434922e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.74026155e-01,  9.92298365e-01,  9.89850163e-01, ...,\n",
       "           2.15345287e+00,  2.14388776e+00,  1.00982606e+00],\n",
       "         [ 1.15461802e+00,  1.49135983e+00,  1.48941362e+00, ...,\n",
       "           3.14961004e+00,  3.14995646e+00,  1.63456714e+00],\n",
       "         [ 1.15080845e+00,  1.49328399e+00,  1.49007165e+00, ...,\n",
       "           3.15124583e+00,  3.15727139e+00,  1.63629985e+00],\n",
       "         ...,\n",
       "         [-4.74477857e-01,  1.17840439e-01, -2.06955805e-01, ...,\n",
       "           3.23712081e-01,  3.00540209e-01,  2.76469707e-01],\n",
       "         [-3.65475655e-01, -9.00731087e-02, -3.27685386e-01, ...,\n",
       "           3.68473142e-01,  2.97051162e-01,  3.37512463e-01],\n",
       "         [-1.09144732e-01, -2.00153157e-01, -2.79196620e-01, ...,\n",
       "           1.17598087e-01,  9.22006071e-02,  1.73297703e-01]],\n",
       "\n",
       "        [[-6.02055788e-02,  3.58067185e-01,  3.60483080e-01, ...,\n",
       "           1.26671895e-01,  1.08526871e-01,  7.65465260e-01],\n",
       "         [-3.96377206e-01,  2.40195125e-01,  2.53951043e-01, ...,\n",
       "           1.87483177e-01,  2.01865181e-01,  1.80358624e+00],\n",
       "         [-3.49532843e-01,  2.86569625e-01,  2.76618838e-01, ...,\n",
       "           2.29672924e-01,  2.14375928e-01,  1.80087614e+00],\n",
       "         ...,\n",
       "         [-1.64316833e-01,  4.83706534e-01,  6.98106527e-01, ...,\n",
       "           1.14048958e-01,  2.43833616e-01,  3.88098806e-01],\n",
       "         [-2.31522560e-01, -8.38577747e-04,  2.27448776e-01, ...,\n",
       "           1.04189587e+00,  7.23776937e-01,  8.47172499e-01],\n",
       "         [ 7.40522385e-01,  6.53991997e-01,  7.49089599e-01, ...,\n",
       "          -1.39352262e-01,  8.16654861e-02,  4.81101692e-01]],\n",
       "\n",
       "        [[-1.18125021e+00, -2.14634418e+00, -2.17475390e+00, ...,\n",
       "          -4.81049395e+00, -4.81908274e+00, -2.52584147e+00],\n",
       "         [ 6.24648213e-01,  4.05711800e-01,  3.97676855e-01, ...,\n",
       "           4.11519140e-01,  4.02848095e-01,  1.21956837e+00],\n",
       "         [ 6.42758608e-01,  4.00062293e-01,  4.30204719e-01, ...,\n",
       "           3.88606876e-01,  3.98993582e-01,  1.23556232e+00],\n",
       "         ...,\n",
       "         [-2.72691756e-01,  3.52589190e-02,  1.16265821e+00, ...,\n",
       "           3.95263910e-01,  3.27884644e-01,  1.23704106e-01],\n",
       "         [-4.58105236e-01,  5.23008347e-01,  6.49500728e-01, ...,\n",
       "           3.28351200e-01,  3.45589727e-01, -6.99554086e-02],\n",
       "         [-1.99936241e-01,  1.61139214e+00,  1.06960988e+00, ...,\n",
       "           1.10859013e+00,  1.21644187e+00,  4.64149177e-01]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-4.35848564e-01, -2.76941627e-01, -2.86430359e-01, ...,\n",
       "           7.58498788e-01,  7.56733000e-01,  4.38061357e-01],\n",
       "         [-3.96352023e-01, -2.71862209e-01, -2.84331471e-01, ...,\n",
       "           7.47735739e-01,  7.46625960e-01,  4.61679697e-01],\n",
       "         [-3.92981797e-01, -2.72107184e-01, -2.70687670e-01, ...,\n",
       "           7.38332450e-01,  7.37986863e-01,  4.65240628e-01],\n",
       "         ...,\n",
       "         [-1.86877549e+00, -2.27427554e+00, -2.35830498e+00, ...,\n",
       "          -1.39870441e+00, -1.32285523e+00, -1.21387565e+00],\n",
       "         [-1.74284554e+00, -2.03332281e+00, -2.27975726e+00, ...,\n",
       "          -1.45715141e+00, -1.37679887e+00, -1.28719878e+00],\n",
       "         [-1.40771985e+00, -1.46523321e+00, -1.65783668e+00, ...,\n",
       "          -9.74298537e-01, -1.01699233e+00, -1.07208538e+00]],\n",
       "\n",
       "        [[ 1.62007079e-01,  4.67999279e-01,  4.79892820e-01, ...,\n",
       "           8.34800303e-01,  8.69134247e-01,  1.78299928e+00],\n",
       "         [-1.59164310e-01,  2.77136207e-01,  3.30293953e-01, ...,\n",
       "           1.96036324e-01,  2.49110416e-01,  1.67158949e+00],\n",
       "         [-1.07872911e-01,  3.24014723e-01,  3.72142613e-01, ...,\n",
       "           2.61011004e-01,  2.26912290e-01,  1.66034949e+00],\n",
       "         ...,\n",
       "         [ 3.99579644e+00,  2.34091982e-01,  9.27853227e-01, ...,\n",
       "          -5.72833300e-01, -2.81613618e-01, -8.57530236e-01],\n",
       "         [ 3.14297223e+00,  1.21219933e+00,  2.13652325e+00, ...,\n",
       "           4.20884550e-01,  3.48329693e-01, -6.55727029e-01],\n",
       "         [ 3.49355149e+00,  2.52715111e+00,  4.56610727e+00, ...,\n",
       "           1.00002825e+00,  1.13164163e+00,  3.69906932e-01]],\n",
       "\n",
       "        [[-1.25432646e+00, -1.49930847e+00, -1.51244235e+00, ...,\n",
       "          -1.48164666e+00, -1.49309897e+00, -1.29796863e+00],\n",
       "         [-1.23248994e+00, -1.64541495e+00, -1.67593575e+00, ...,\n",
       "          -1.79481268e+00, -1.80478776e+00, -1.50515997e+00],\n",
       "         [-1.24115944e+00, -1.67595601e+00, -1.66321361e+00, ...,\n",
       "          -1.81898475e+00, -1.82345629e+00, -1.49373126e+00],\n",
       "         ...,\n",
       "         [-3.30369568e+00, -3.02207494e+00, -2.82705164e+00, ...,\n",
       "          -1.75334966e+00, -1.71825612e+00, -1.62301278e+00],\n",
       "         [-3.08956075e+00, -2.70376897e+00, -3.12073064e+00, ...,\n",
       "          -2.21377182e+00, -2.02596736e+00, -1.84267581e+00],\n",
       "         [-2.88644385e+00, -2.61959314e+00, -3.34184790e+00, ...,\n",
       "          -1.70126545e+00, -1.76340973e+00, -1.76434898e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.74026215e-01,  9.92298365e-01,  9.89850163e-01, ...,\n",
       "           2.15345311e+00,  2.14388776e+00,  1.00982606e+00],\n",
       "         [ 1.15461791e+00,  1.49135971e+00,  1.48941362e+00, ...,\n",
       "           3.14960957e+00,  3.14995646e+00,  1.63456714e+00],\n",
       "         [ 1.15080845e+00,  1.49328399e+00,  1.49007165e+00, ...,\n",
       "           3.15124583e+00,  3.15727091e+00,  1.63629985e+00],\n",
       "         ...,\n",
       "         [-4.74477857e-01,  1.17840365e-01, -2.06955761e-01, ...,\n",
       "           3.23712111e-01,  3.00540149e-01,  2.76469707e-01],\n",
       "         [-3.65475625e-01, -9.00730863e-02, -3.27685356e-01, ...,\n",
       "           3.68473113e-01,  2.97051132e-01,  3.37512493e-01],\n",
       "         [-1.09144747e-01, -2.00153217e-01, -2.79196560e-01, ...,\n",
       "           1.17598124e-01,  9.22005996e-02,  1.73297703e-01]],\n",
       "\n",
       "        [[-6.02055527e-02,  3.58067185e-01,  3.60483080e-01, ...,\n",
       "           1.26671866e-01,  1.08526990e-01,  7.65465200e-01],\n",
       "         [-3.96377265e-01,  2.40195185e-01,  2.53951073e-01, ...,\n",
       "           1.87483147e-01,  2.01865152e-01,  1.80358636e+00],\n",
       "         [-3.49532813e-01,  2.86569595e-01,  2.76618898e-01, ...,\n",
       "           2.29672894e-01,  2.14375988e-01,  1.80087626e+00],\n",
       "         ...,\n",
       "         [-1.64316818e-01,  4.83706564e-01,  6.98106289e-01, ...,\n",
       "           1.14048958e-01,  2.43833527e-01,  3.88098776e-01],\n",
       "         [-2.31522456e-01, -8.38647014e-04,  2.27448612e-01, ...,\n",
       "           1.04189587e+00,  7.23777056e-01,  8.47172499e-01],\n",
       "         [ 7.40522444e-01,  6.53992057e-01,  7.49089777e-01, ...,\n",
       "          -1.39352277e-01,  8.16654041e-02,  4.81101692e-01]],\n",
       "\n",
       "        [[-1.18125021e+00, -2.14634418e+00, -2.17475390e+00, ...,\n",
       "          -4.81049442e+00, -4.81908274e+00, -2.52584124e+00],\n",
       "         [ 6.24648273e-01,  4.05711591e-01,  3.97676885e-01, ...,\n",
       "           4.11518753e-01,  4.02847946e-01,  1.21956921e+00],\n",
       "         [ 6.42758906e-01,  4.00061995e-01,  4.30204809e-01, ...,\n",
       "           3.88606519e-01,  3.98993731e-01,  1.23556292e+00],\n",
       "         ...,\n",
       "         [-2.72691607e-01,  3.52590457e-02,  1.16265774e+00, ...,\n",
       "           3.95263702e-01,  3.27884644e-01,  1.23704217e-01],\n",
       "         [-4.58105206e-01,  5.23008347e-01,  6.49500370e-01, ...,\n",
       "           3.28351408e-01,  3.45589966e-01, -6.99554309e-02],\n",
       "         [-1.99936301e-01,  1.61139178e+00,  1.06960976e+00, ...,\n",
       "           1.10859025e+00,  1.21644175e+00,  4.64149207e-01]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.forward(X).detach().cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
